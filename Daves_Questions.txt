
I'm witnessing and have measured behavior of Python memory leaks which appear to change their severity (or existence at all sometimes) based on the allocator selected or the moment I run profiling tests (sometimes the issue goes away by itself). Specifically, I'm making use of PyArrow, DuckDB to extract PyArrow tables, and Parsl (a Pythonic workflow package which has multi-thread and multi-process capabilities). I think the things that make me scratch my head the most are:
- What happens and how do we best manage when software makes use of potentially multiple memory allocators (how does multiplexing work, if it all)?
- If I'm observing only one memory allocator's performance, can I accurately make hypotheses about the others at play?
- When dealing with non-Python-native memory allocators through Python, how do we best and most [computer]-scientifically measure performance profiles?
- Would / could weak references or data copies be used to avoid unnecessary memory consumed through Pythonic function arguments (i.e. the space args take when a function object is implemented)?
- How does heap memory effect resident memory (if at all)?


Too new to Python to know all of what you are talking about.
- What allocators, multiplexing? …I assume the allocators include their own garbage collection and all have claims they work perfectly?
   - I’ve worked with custom allocators that work within a small set of memory allocation from Java. We were recycling giant arrays of the same size.
- weak references? …“no methods or attributes” You already save memory in Python because it passes object refernces (based on a quick and dirty google search). You should try a quick experiment where you have a program that creates 1000 object instances, and then 1000 more and compare that to passing the original 1000 to a function. If you look at the memory consumed (and force the function call to last long enough to look) you should see the function call doesn’t consume a bunch more memory, not a second batch of 1000 anyway.
- again weak references, but in refernece to not run of the mill objects, but function objects? How many do you have and how much memory do you think a rerefence to a function takes?

I need to read up on resident memory and commits etc, basically how to read the memory numbers out of top or htop. Basically heap memory is where allocated objects go and will increase the memory the program uses. Resident, has been defined as that what is actually in memory and not on disk (decades ago), and now is more about actually used memory rather than reserved memory. Basically more heap used would mean more resident. But if by heap, you mean the maximum heap size, then no.

Thanks! I'll try to address some of those questions:
- Multiple allocators: in CytoTable I'm using at least (C) malloc (DuckDB) mimalloc (PyArrow by way of Cython), and I believe pymalloc (as a Python default for some objects). I can enforce PyArrow to run using malloc at a performance loss (mimalloc and optional jemalloc perform better with that library), but I don't think I can do this for pymalloc.
- Weak references: built-in weakref for managing references which are garbage collectable in nested or dependent data structures. I use nested dictionary and list structures to help keep track of map-reduce style mapped chunks which are later reduced to a/or many singular file(s). Here I wonder if sending a weakref of nested complex data structures (like below) as a arg for a function parameter would alleviate some of the memory stress. I don't understand enough about how this works just yet to know whether it'd work at all or just be added complexity without benefit.
- For the function parameters, sometimes these are receiving complex data structures of 1000's of column names / dtypes (as List[Dict[str:str]]  type, lists of dictionaries with string keys and values) for use in making sure schema are treated uniformly from non-data-type-static formats (CSV's, SQLite). These aren't much on their own but can have an impact when calling the function which receives this data 100's of times as a "mapped" call for chunking operations against the data source.
- Heap memory: I found that PyArrow is likely consuming extremely large amounts of heap memory (GB's compared to relative MB's for resident consumption during the same process). It "feels" like a maximum threshold in order to provide C-level operations the "space" they need to do their work quickly (with speed/low time duration as the preference over memory conservation), but I have no proof of this. I also don't understand whether this large maximum in the presence of questionable object references for Python would cause an exacerbation of a leak (when otherwise with low heap / memory maximums the allocator would decide it's time to clean up some objects in residence).
